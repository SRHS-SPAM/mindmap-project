# AI ëª¨ë¸ê³¼ ê´€ë ¨ëœ ë¡œì§ì´ í¬í•¨ëœ íŒŒì¼ì…ë‹ˆë‹¤.
import os
import json
from typing import List, Dict, Any, Optional
from ..schemas import ChatMessage, AIAnalysisResult, MindMapData, MindMapNodeBase
# DB ì„¸ì…˜ íƒ€ì…ì„ ì •ì˜í•˜ê¸° ìœ„í•´ ORM ëª¨ë¸ì„ importí•©ë‹ˆë‹¤.
from ..models import MindMapNode as ORMMindMapNode

import vertexai
from vertexai.generative_models import GenerativeModel, GenerationConfig

from pydantic import BaseModel, Field
from sqlalchemy.orm import Session # ì„¸ì…˜ íƒ€ì… ëª…ì‹œ

# ğŸ’¡ [Vertex AI ì„¤ì •]
PROJECT_ID = os.getenv("GCP_PROJECT_ID", "minmap-476213") 
REGION = os.getenv("GCP_REGION", "asia-northeast3") # ì„œìš¸ ë¦¬ì „
# ğŸš¨ [ìˆ˜ì •] gemini-1.5-pro ëŒ€ì‹  ê´‘ë²”ìœ„í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
GEMINI_MODEL = "gemini-2.5-flash"

# ğŸ’¡ [Vertex AI Client ì´ˆê¸°í™”]
try:
    vertexai.init(project=PROJECT_ID, location=REGION)
    # GenerativeModel ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    MODEL_CLIENT = GenerativeModel(model_name=GEMINI_MODEL) # â¬…ï¸ ì´ì œ gemini-2.5-flashë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    CLIENT = "Ready" 
    print(f"âœ… Vertex AI ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ! (Model: {GEMINI_MODEL}, Project: {PROJECT_ID}, Region: {REGION})")
except Exception as e:
    print(f"âŒ Vertex AI GenerativeModel ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    CLIENT = None


# Node ë° Link êµ¬ì¡°ë¥¼ ë§Œë“¤ê¸° ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def create_node(id: str, type: str, title: str, desc: str, connections: List[str] = None) -> Dict[str, Any]:
    return MindMapNodeBase(
        id=id,
        node_type=type,
        title=title,
        description=desc,
        connections=[{"target_id": tid} for tid in (connections or [])]
    ).model_dump() 

def create_link(source: str, target: str) -> Dict[str, str]:
    return {"source": source, "target": target}


# ğŸ’¡ ë§ˆì¸ë“œë§µ ìƒì„±ì„ ìœ„í•œ Pydantic ìŠ¤í‚¤ë§ˆ
class MindMapNodeOutput(BaseModel):
    id: str = Field(..., description="ê³ ìœ í•œ ë…¸ë“œ ID (ì˜ˆ: 'core-1')")
    node_type: str = Field(..., description="ë…¸ë“œì˜ ê³„ì¸µ ë ˆë²¨ ('core', 'major', 'minor' ì¤‘ í•˜ë‚˜)")
    title: str = Field(..., description="ë…¸ë“œì˜ í•µì‹¬ ì œëª©")
    # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] Optional[str]ì„ ì œê±°í•˜ê³ , ê¸°ë³¸ê°’ì„ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ Pydantic ìŠ¤í‚¤ë§ˆê°€ 
    # 'ë¬¸ìì—´ ë˜ëŠ” Null' ëŒ€ì‹  'ê¸°ë³¸ê°’ì´ Nullì¸ ë¬¸ìì—´'ë¡œ ë³€í™˜ë˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
    description: str = Field(None, description="ë…¸ë“œì˜ ìƒì„¸ ë‚´ìš©") 
    connections: List[Dict[str, str]] = Field(default_factory=list, description="ì—°ê²° ì •ë³´")

class MindMapDataOutput(BaseModel):
    nodes: List[MindMapNodeOutput] = Field(..., description="ë§ˆì¸ë“œë§µ ë…¸ë“œ ëª©ë¡")
    links: List[Dict] = Field(default_factory=list, description="ë…¸ë“œ ê°„ ì—°ê²°")


# === AI ì¶”ì²œ ê¸°ëŠ¥ ===
def recommend_map_improvements(map_data: Dict[str, Any], chat_history: List[ChatMessage]) -> str:
    """
    ë§ˆì¸ë“œë§µì„ ê¸°ë°˜ìœ¼ë¡œ ê°œì„  ì‚¬í•­ì„ ì¶”ì²œí•˜ëŠ” AI í•¨ìˆ˜. (500ì ì´ë‚´)
    """
    current_map_json = json.dumps(map_data, ensure_ascii=False, indent=2)
    recent_chat_text = "\n".join([
        f"[{chat.user_id} - {chat.timestamp.strftime('%H:%M')}] {chat.content}" 
        for chat in chat_history[-20:]
    ])

    prompt = f"""
ë‹¹ì‹ ì€ í˜‘ì—… í”„ë¡œì íŠ¸ì˜ ì§„í–‰ ìƒí™©ì„ ë¶„ì„í•˜ê³  ë§ˆì¸ë“œë§µ êµ¬ì¡°ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ê°œì„  ì‚¬í•­ì„ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ AIì…ë‹ˆë‹¤.
ì‚¬ìš©ìë“¤ì´ ì±„íŒ…ìœ¼ë¡œ ë…¼ì˜í•œ ë‚´ìš©ê³¼ í˜„ì¬ ë§ˆì¸ë“œë§µ êµ¬ì¡°ë¥¼ ë¹„êµí•˜ì—¬, ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ì´ìƒì˜ ê´€ì ì—ì„œ 500ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

**ì£¼ìš” ì¶”ì²œ ê´€ì :**
1. **êµ¬ì¡° ê°œì„ :** ëˆ„ë½ëœ í•µì‹¬ ì£¼ì œ/ëŒ€ì£¼ì œ/ì†Œì£¼ì œê°€ ìˆëŠ”ì§€, ë…¸ë“œê°€ ë„ˆë¬´ ë§ê±°ë‚˜ ì ì€ì§€, ë¶ˆí•„ìš”í•˜ê²Œ ë³µì¡í•œ ì—°ê²°ì´ ìˆëŠ”ì§€.
2. **ë…¼ì˜ ì‹¬í™”:** ì±„íŒ…ì—ì„œ ì–¸ê¸‰ë˜ì—ˆìœ¼ë‚˜ ë§ˆì¸ë“œë§µì— ë°˜ì˜ë˜ì§€ ì•Šì€ ì¤‘ìš”í•œ í›„ì† ë…¼ì˜ ì£¼ì œê°€ ìˆëŠ”ì§€.
3. **ì •ë¦¬ ì œì•ˆ:** ëª¨í˜¸í•˜ê±°ë‚˜ ë¶ˆì™„ì „í•œ ë…¸ë“œë¥¼ ì–´ë–»ê²Œ ìˆ˜ì •í•˜ë©´ ì¢‹ì„ì§€.

ë‹µë³€ì€ Markdown í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë¡œë§Œ ë°˜í™˜í•˜ê³ , JSON í˜•ì‹ì´ë‚˜ ë‹¤ë¥¸ ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.

---
í˜„ì¬ ë§ˆì¸ë“œë§µ êµ¬ì¡°:
{current_map_json}

---
ìµœê·¼ ì±„íŒ… ê¸°ë¡:
{recent_chat_text}

---
ì´ ë‘ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, í”„ë¡œì íŠ¸ ì§„í–‰ ë° ë§ˆì¸ë“œë§µ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì¶”ì²œ ì‚¬í•­ì„ 500ì ì´ë‚´ë¡œ ì œì‹œí•´ ì£¼ì„¸ìš”.
"""
    
    if not CLIENT:
        return "Vertex AI Clientê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    try:
        response = MODEL_CLIENT.generate_content(
            contents=[prompt],
            generation_config=GenerationConfig(
                temperature=0.7,
                max_output_tokens=1024 # 500ì ì´ë‚´ë¥¼ ìœ„í•´ í† í°ì„ ë„‰ë„‰íˆ ì„¤ì •
            )
        )
        return response.text

        
    except Exception as e:
        print(f"Vertex AI ì¶”ì²œ API ìš”ì²­ ì˜¤ë¥˜: {e}")
        return "AI ë¶„ì„ ì„œë²„ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."


# === ì‹¤ì œ AI ë¶„ì„ ë° ë§ˆì¸ë“œë§µ ìƒì„± í•¨ìˆ˜ ===
def analyze_chat_and_generate_map(
    project_id: int, 
    chat_history: List[ChatMessage], 
    last_processed_chat_id: int,
    db_session: Session
) -> AIAnalysisResult:
    """
    ì±„íŒ… ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ Vertex AIë¥¼ í†µí•´ ë§ˆì¸ë“œë§µ êµ¬ì¡°ë¥¼ ìƒì„±í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # # ğŸ’¡ [ì„ì‹œ ë””ë²„ê¹… ì½”ë“œ ì‹œì‘] 
    # try:
    #     if CLIENT:
    #         # ì•„ì£¼ ê°„ë‹¨í•œ API í˜¸ì¶œì„ ì‹œë„í•©ë‹ˆë‹¤.
    #         test_response = MODEL_CLIENT.generate_content(
    #             contents=["Hello, Gemini. What is the capital of France?"],
    #             generation_config=GenerationConfig(max_output_tokens=10)
    #         )
    #         print(f"âœ… DEBUG: Basic API Call Success. Response: {test_response.text}")
    #     else:
    #         print("âŒ DEBUG: CLIENT is None.")
    # except Exception as e:
    #     # ì´ ì—ëŸ¬ê°€ ì„œë²„ ë¡œê·¸ì— ì¶œë ¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    #     print(f"ğŸš¨ğŸš¨ğŸš¨ DEBUG FATAL API ERROR DURING SIMPLE TEST: {e} ğŸš¨ğŸš¨ğŸš¨")
    # # ğŸ’¡ [ì„ì‹œ ë””ë²„ê¹… ì½”ë“œ ë]
    
    # 1. ìƒˆë¡œ ë¶„ì„í•  ì±„íŒ… ê¸°ë¡ í•„í„°ë§
    new_chat_history = [chat for chat in chat_history if chat.id > (last_processed_chat_id or 0)]

    # if not new_chat_history:
    #     print("ìƒˆë¡œ ë¶„ì„í•  ì±„íŒ…ì´ ì—†ìŠµë‹ˆë‹¤.")
    #     return AIAnalysisResult(
    #         is_success=True,
    #         last_chat_id=last_processed_chat_id,
    #         mind_map_data=MindMapData(nodes=[], links=[]) 
    #     )

    # ìƒˆë¡œìš´ ì±„íŒ…ì´ ì—†ì–´ë„ ì „ì²´ ì±„íŒ… ê¸°ë¡ì„ ì‚¬ìš©í•˜ì—¬ LLMì„ í˜¸ì¶œí•˜ë„ë¡ new_chat_textë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    # ğŸ’¡ [ìˆ˜ì •] new_chat_textë¥¼ ì „ì²´ chat_historyë¡œ êµ¬ì„± (ê°•ì œ í˜¸ì¶œ ëª©ì )
    new_chat_text = "\n".join([f"[{chat.user_id}] {chat.content}" for chat in chat_history])
    last_chat_id = chat_history[-1].id if chat_history else (last_processed_chat_id or 0)

    # ğŸš¨ğŸš¨ğŸš¨ ë””ë²„ê¹…ì„ ìœ„í•œ ì½”ë“œ ì¶”ê°€ ğŸš¨ğŸš¨ğŸš¨
    print(f"ğŸš¨ğŸš¨ New Chat Text Content:\n{new_chat_text}\nğŸš¨ğŸš¨ End of New Chat Text") 
    # ğŸš¨ğŸš¨ğŸš¨ ë””ë²„ê¹… ì½”ë“œ ë ğŸš¨ğŸš¨ğŸš¨

    # 3. ê¸°ì¡´ ë§ˆì¸ë“œë§µ ì •ë³´ ë¡œë“œ
    existing_nodes = db_session.query(ORMMindMapNode).filter(
        ORMMindMapNode.project_id == project_id
    ).all()
    
    existing_map_info = "\n".join([
        f"- ID: {node.id}, Title: {node.title}, Description: {node.description}" 
        for node in existing_nodes
    ]) if existing_nodes else "ê¸°ì¡´ ë§ˆì¸ë“œë§µ ì •ë³´ ì—†ìŒ."

    # JSON ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
    prompt = f"""
ë‹¹ì‹ ì€ ì‚¬ìš©ìë“¤ì˜ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ë§ˆì¸ë“œë§µ(MindMap) ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ AIì…ë‹ˆë‹¤.
**ë‹¹ì‹ ì€ ì•„ë˜ [ì±„íŒ… ë‚´ìš©] ì„¹ì…˜ì— ì œê³µëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì£¼ì œì— ë§ëŠ” ë§ˆì¸ë“œë§µì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.**

**ğŸš¨ [ê°•ì¡°] ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ìš”ì²­ëœ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì™„ë²½íˆ ì¤€ìˆ˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. JSON ë§ˆí¬ë‹¤ìš´ ë¸”ë¡(```json)ì´ë‚˜ ë‹¤ë¥¸ ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ JSON ì•ë’¤ì— ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.**

**[ì±„íŒ… ë‚´ìš©] (ì´ê²ƒì´ ë§ˆì¸ë“œë§µì˜ ê·¼ê±°ê°€ ë©ë‹ˆë‹¤):**
{new_chat_text}

**ë§ˆì¸ë“œë§µ ê³„ì¸µ êµ¬ì¡°:**
1. 'í•µì‹¬ ì£¼ì œ' (core): ëŒ€í™”ì˜ ê°€ì¥ ì¤‘ì‹¬ì ì¸ ëª©í‘œ ë˜ëŠ” ì£¼ì œ (ì˜ˆ: "ì ì‹¬ ë©”ë‰´ ë¦¬ìŠ¤íŠ¸")
2. 'ëŒ€ì£¼ì œ' (major): í•µì‹¬ ì£¼ì œë¥¼ ì´ë£¨ëŠ” ì£¼ìš” êµ¬ì„± ìš”ì†Œ ë˜ëŠ” ë‹¨ê³„ (ì˜ˆ: "í•œì‹", "ì–‘ì‹", "ì¤‘ì‹")
3. 'ì†Œì£¼ì œ' (minor): ëŒ€ì£¼ì œë¥¼ ìƒì„¸í™”í•˜ëŠ” ì„¸ë¶€ í•­ëª© ë˜ëŠ” ì•„ì´ë””ì–´ (ì˜ˆ: "ë¹„ë¹”ë°¥", "íƒ•ìˆ˜ìœ¡")

**ì œì•½ ì¡°ê±´:**
- ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•˜ë©°, ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
- ë…¸ë“œ IDëŠ” ê³ ìœ í•œ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- connections í•„ë“œëŠ” ë…¸ë“œ ê°„ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ë°˜ë“œì‹œ ì¡´ì¬í•˜ëŠ” ë…¸ë“œì˜ IDë¥¼ ê°€ë¦¬ì¼œì•¼ í•©ë‹ˆë‹¤.
- **[í•µì‹¬]** **ìœ„ ì±„íŒ… ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë§ˆì¸ë“œë§µ ë…¸ë“œë¥¼ ì ê·¹ì ìœ¼ë¡œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. íŠ¹íˆ, core ë…¸ë“œëŠ” ë°˜ë“œì‹œ "ì ì‹¬ ë©”ë‰´ ë¦¬ìŠ¤íŠ¸"ì™€ ê°™ì´ ëŒ€í™” ì£¼ì œë¥¼ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.**
- ê¸°ì¡´ ë§ˆì¸ë“œë§µ ì •ë³´ê°€ ìˆë‹¤ë©´ ì—…ë°ì´íŠ¸ë¥¼ ê³ ë ¤í•´ì•¼ í•˜ì§€ë§Œ, í˜„ì¬ëŠ” ìƒˆë¡œ ìƒì„±í•˜ëŠ” ë° ì§‘ì¤‘í•´ì£¼ì„¸ìš”.
- **[í•µì‹¬]** **ìœ„ [ì±„íŒ… ë‚´ìš©] ì„¹ì…˜ì— ì‹¤ì œ ëŒ€í™” ë‚´ìš©ì´ ìˆë‹¤ë©´, ë‹¹ì‹ ì€ ë¬´ì¡°ê±´ ê·¸ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì¸ë“œë§µì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. "ë¶„ì„í•  ëŒ€í™” ë‚´ìš© ì—†ìŒ"ê³¼ ê°™ì€ ê¸°ë³¸ í…œí”Œë¦¿ì„ ë°˜í™˜í•´ì„œëŠ” ì ˆëŒ€ ì•ˆ ë©ë‹ˆë‹¤.**
- **[í•µì‹¬]** **core ë…¸ë“œì˜ `title`ì€ ì±„íŒ… ë‚´ìš©ì˜ í•µì‹¬ ì£¼ì œ (ì˜ˆ: "ì ì‹¬ ë©”ë‰´ ë¦¬ìŠ¤íŠ¸")ë¥¼ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.**
- ê¸°ì¡´ ë§ˆì¸ë“œë§µ ì •ë³´ê°€ ìˆë‹¤ë©´ ì—…ë°ì´íŠ¸ë¥¼ ê³ ë ¤í•´ì•¼ í•˜ì§€ë§Œ, í˜„ì¬ëŠ” ìƒˆë¡œ ìƒì„±í•˜ëŠ” ë° ì§‘ì¤‘í•´ì£¼ì„¸ìš”.

**ê¸°ì¡´ ë§ˆì¸ë“œë§µ ì •ë³´:**
{existing_map_info}

**ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ:**
{{
    "nodes": [
        {{
            "id": "core-1",
            "node_type": "core",  // ğŸ’¡ [ìˆ˜ì •] ì‘ë‹µ ì˜ˆì‹œì˜ 'í•µì‹¬ ì£¼ì œ'ë¥¼ ì‹¤ì œ node_typeì¸ 'core'ë¡œ ìˆ˜ì •
            "title": "í”„ë¡œì íŠ¸ ëª©í‘œ",
            "description": "í”„ë¡œì íŠ¸ì˜ ì „ë°˜ì ì¸ ëª©í‘œ ì„¤ëª…",
            "connections": [{{"target_id": "major-1"}}]
        }},
        {{
            "id": "major-1",
            "node_type": "major", // ğŸ’¡ [ìˆ˜ì •] ì‘ë‹µ ì˜ˆì‹œì˜ 'ëŒ€ì£¼ì œ'ë¥¼ ì‹¤ì œ node_typeì¸ 'major'ë¡œ ìˆ˜ì •
            "title": "ì²« ë²ˆì§¸ ì£¼ìš” ë‹¨ê³„",
            "description": "ìƒì„¸ ì„¤ëª…",
            "connections": [{{"target_id": "core-1"}}, {{"target_id": "minor-1"}}]
        }}
    ],
    "links": [
        {{"source": "core-1", "target": "major-1"}},
        {{"source": "major-1", "target": "minor-1"}}
    ]
}}

---
ìƒˆë¡œ ì—…ë°ì´íŠ¸ëœ ì±„íŒ… ê¸°ë¡:
{new_chat_text}

---
ìœ„ ì±„íŒ… ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ë§ˆì¸ë“œë§µ JSONì„ ìƒì„±í•´ì£¼ì„¸ìš”.
"""
    # ğŸ’¡ [ì¶”ê°€] ë³€ìˆ˜ ì„ ì–¸: ì–´ë–¤ ì˜ˆì™¸ê°€ ë°œìƒí•˜ë“  ì´ ë³€ìˆ˜ë¥¼ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
    json_string = "INITIALIZATION_FAILED" # ê¸°ë³¸ê°’ ì„¤ì •
    
    if not CLIENT:
        return AIAnalysisResult(
            is_success=False, 
            last_chat_id=last_chat_id, 
            mind_map_data=MindMapData(nodes=[], links=[])
        )

    try:
        json_schema_dict = MindMapDataOutput.model_json_schema(
            by_alias=True, 
            # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] ref_templateì„ '#/defs/{model}'ë¡œ ë³€ê²½í•˜ì—¬ 
            # Pydanticì´ ìƒì„±í•˜ëŠ” $ref ì°¸ì¡° ê²½ë¡œë¥¼ Vertex AIê°€ ê¸°ëŒ€í•˜ëŠ” ê²½ë¡œì™€ ì¼ì¹˜ì‹œí‚µë‹ˆë‹¤.
            ref_template="#/defs/{model}" 
        )
        
        # ğŸ’¡ [ì¬í™•ì¸] Vertex AIëŠ” 'definitions' ëŒ€ì‹  'defs' í‚¤ë¥¼ ê¸°ëŒ€í•©ë‹ˆë‹¤.
        # Pydanticì´ ref_templateì„ '#/defs'ë¡œ ì„¤ì •í–ˆìœ¼ë¯€ë¡œ, 
        # ì´ì œ root ìŠ¤í‚¤ë§ˆì˜ ì •ì˜ í‚¤ë„ 'defs'ë¡œ ë³€ê²½í•©ë‹ˆë‹¤. (ì´ì „ ë‹¨ê³„ì—ì„œ í–ˆë˜ ë¡œì§ ì¬í™œìš©)
        if 'definitions' in json_schema_dict:
            json_schema_dict['defs'] = json_schema_dict.pop('definitions')
        # ë§Œì•½ 'definitions'ì´ ì—†ë‹¤ë©´, Pydantic v2ëŠ” ì´ë¯¸ 'defs'ë¥¼ ì‚¬ìš©í•˜ê³  ìˆì„ ìˆ˜ ìˆìœ¼ë‚˜, 
        # ì•ˆì „ì„ ìœ„í•´ í‚¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.


        response = MODEL_CLIENT.generate_content(
            contents=[prompt],
            generation_config=GenerationConfig(
                temperature=0.7,
                response_mime_type="application/json",
                response_schema=json_schema_dict, # â¬…ï¸ JSON ìŠ¤í‚¤ë§ˆ ë”•ì…”ë„ˆë¦¬ ì „ë‹¬
                max_output_tokens=4096
            )
        )
        
        # ğŸ’¡ [í•µì‹¬ ì¶”ê°€] LLMì´ ë°˜í™˜í•œ JSON ì›ë³¸ í…ìŠ¤íŠ¸ ê°•ì œ ì¶œë ¥
        json_string = response.text
        print("ğŸ’¡ğŸ’¡ğŸ’¡ LLM ì‘ë‹µ ì›ë³¸ JSON í…ìŠ¤íŠ¸: ğŸ’¡ğŸ’¡ğŸ’¡")
        print(json_string)
        print("-----------------------------------------")
        
        # 2. JSON íŒŒì‹± ë° ë°ì´í„° ìœ íš¨ì„± ê²€ì¦

        if not response.text:
            # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì•ˆì „ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
            reason = response.candidates[0].finish_reason.name if response.candidates else "UNKNOWN"
            print(f"ğŸš¨ğŸš¨ ëª¨ë¸ ì‘ë‹µ ì‹¤íŒ¨: í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ. Finish Reason: {reason}")
            
            # ëª¨ë¸ ì‘ë‹µ ê°ì²´ ì „ì²´ë¥¼ ì¶œë ¥í•˜ì—¬ ì•ˆì „ í•„í„° ì •ë³´ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
            print(f"ğŸš¨ğŸš¨ ì‘ë‹µ ê°ì²´ ì „ë¬¸:\n{response}") 
            
            # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë¯€ë¡œ json_stringì„ 'MODEL_BLOCKED'ë¡œ ì„¤ì •í•˜ê³  ì‹¤íŒ¨ ë°˜í™˜ ë¡œì§ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.
            json_string = "MODEL_BLOCKED" 
            
            # ì¸ìœ„ì ìœ¼ë¡œ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œì¼œ ì•„ë˜ì˜ ìƒì„¸ ë¡œê¹… ë¸”ë¡ìœ¼ë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.
            raise ValueError("Model response was blocked or empty.")
    
        # 2. ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±
        # ğŸ’¡ [ìˆ˜ì •] response.textë¥¼ ë°”ë¡œ í• ë‹¹
        json_string = response.text
        
        # JSON íŒŒì‹± ì „ ì •ë¦¬ (í˜¹ì‹œ ëª¨ë¥¼ ì¶”ê°€ í…ìŠ¤íŠ¸ ì œê±°)
        json_string = json_string.strip()
        if json_string.startswith("```json"):
            json_string = json_string[7:]
        if json_string.startswith("```"):
            json_string = json_string[3:]
        if json_string.endswith("```"):
            json_string = json_string[:-3]
        json_string = json_string.strip()
        
        map_json = json.loads(json_string)

        # 2. Pydantic ëª¨ë¸ë¡œ ìœ íš¨ì„± ê²€ì‚¬
        validated_data = MindMapDataOutput(**map_json)
        
        # 3. schemas.pyì˜ MindMapData êµ¬ì¡°ì— ë§ê²Œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        # ğŸš¨ [í•µì‹¬ ìˆ˜ì •] validated_data.nodes ë¦¬ìŠ¤íŠ¸ì˜ ê° Pydantic ê°ì²´ë¥¼ .model_dump()ë¥¼ ì‚¬ìš©í•˜ì—¬
        # ì›ì‹œ ë”•ì…”ë„ˆë¦¬(DB/ORM ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœ)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        # MindMapNodeOutput ê°ì²´ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¼ë°˜ ë”•ì…”ë„ˆë¦¬ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        converted_nodes = []
        for node in validated_data.nodes:
            node_dict = node.model_dump(mode='json')
            # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] DB ORMì— ì €ì¥ë˜ê¸° ì „ì— connections í•„ë“œë¥¼ ì œê±°
            if 'connections' in node_dict:
                del node_dict['connections'] 
            
            converted_nodes.append(node_dict)

        mind_map_data = MindMapData(
            nodes=converted_nodes, # connectionsê°€ ì œê±°ëœ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©
            links=validated_data.links 
        )
                
        return AIAnalysisResult(
            is_success=True,
            last_chat_id=last_chat_id,
            mind_map_data=mind_map_data
        )

    except (json.JSONDecodeError, KeyError, ValueError) as e:
        print(f"ğŸš¨ Vertex AI ì‘ë‹µ íŒŒì‹± ë˜ëŠ” Pydantic ìœ íš¨ì„± ê²€ì‚¬ ì˜¤ë¥˜: {e}")
        # ğŸ’¡ [ìˆ˜ì •] ì´ì œ json_stringì´ ì™¸ë¶€ì—ì„œ ì„ ì–¸ë˜ì–´ ì•ˆì „í•˜ê²Œ ì ‘ê·¼ ê°€ëŠ¥
        print(f"ğŸš¨ğŸš¨ JSON ë””ì½”ë”© ì‹¤íŒ¨ ì›ë³¸ í…ìŠ¤íŠ¸:\n--- START ---\n{json_string}\n--- END ---") 
        return AIAnalysisResult(
            is_success=False, 
            last_chat_id=last_chat_id, 
            mind_map_data=MindMapData(nodes=[], links=[])
        )
    except Exception as e:
        print(f"ğŸš¨ğŸš¨ ìµœì¢… Vertex AI API ìš”ì²­ ì˜¤ë¥˜ (ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜): {e}")
        print(f"ğŸš¨ğŸš¨ ë§ˆì§€ë§‰ íŒŒì‹± ì‹œë„ í…ìŠ¤íŠ¸:\n--- LAST ATTEMPT ---\n{json_string}\n--- END ---") 
        return AIAnalysisResult(
            is_success=False, 
            last_chat_id=last_chat_id, 
            mind_map_data=MindMapData(nodes=[], links=[])
        )
